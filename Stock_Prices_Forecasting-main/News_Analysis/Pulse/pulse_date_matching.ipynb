{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows loaded: 421971\n",
      "                                            headline  \\\n",
      "0  Production outages in Asia lend slight support...   \n",
      "1  UK consumers suffer longest decline in spendin...   \n",
      "2  Market Now: Gammon Infra, GVK Power Infra surg...   \n",
      "3  Global markets: Brightening economy sets euro ...   \n",
      "4  Relying on schemes like Swachh Bharat alone wo...   \n",
      "\n",
      "                                                 url         publish_date  \n",
      "0  http://feeds.reuters.com/~r/reuters/INbusiness...  2017-06-30 15:03:52  \n",
      "1  http://feeds.reuters.com/~r/reuters/INbusiness...  2017-06-30 15:03:11  \n",
      "2  http://economictimes.indiatimes.com/markets/st...  2017-06-30 15:01:36  \n",
      "3  http://feeds.reuters.com/~r/reuters/INbusiness...  2017-06-30 15:00:36  \n",
      "4  http://www.business-standard.com/article/econo...  2017-06-30 14:59:00  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the news dataset, specifying that any extra commas are part of quoted titles\n",
    "# This will generate warnings for problematic lines\n",
    "news_df = pd.read_csv('pulse.csv', names=['headline', 'url', 'publish_date'], header=None, quotechar='\"', on_bad_lines='skip')\n",
    "\n",
    "# After loading the data, print the number of rows in the DataFrame\n",
    "print(f\"Total rows loaded: {len(news_df)}\")\n",
    "\n",
    "# Optionally, print the first few rows to verify\n",
    "print(news_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publish_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Production outages in Asia lend slight support...</td>\n",
       "      <td>http://feeds.reuters.com/~r/reuters/INbusiness...</td>\n",
       "      <td>2017-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UK consumers suffer longest decline in spendin...</td>\n",
       "      <td>http://feeds.reuters.com/~r/reuters/INbusiness...</td>\n",
       "      <td>2017-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Market Now: Gammon Infra, GVK Power Infra surg...</td>\n",
       "      <td>http://economictimes.indiatimes.com/markets/st...</td>\n",
       "      <td>2017-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Global markets: Brightening economy sets euro ...</td>\n",
       "      <td>http://feeds.reuters.com/~r/reuters/INbusiness...</td>\n",
       "      <td>2017-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Relying on schemes like Swachh Bharat alone wo...</td>\n",
       "      <td>http://www.business-standard.com/article/econo...</td>\n",
       "      <td>2017-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421966</th>\n",
       "      <td>Chennai Angels invests in SparesHub owner Iradium</td>\n",
       "      <td>http://www.thehindu.com/business/Industry/chen...</td>\n",
       "      <td>1970-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421967</th>\n",
       "      <td>Task force formed on aviation</td>\n",
       "      <td>http://www.thehindu.com/business/Economy/task-...</td>\n",
       "      <td>1970-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421968</th>\n",
       "      <td>Biological E in vaccine tie-up with Takeda</td>\n",
       "      <td>http://www.thehindu.com/business/Economy/biolo...</td>\n",
       "      <td>1970-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421969</th>\n",
       "      <td>HPCL joins talks for Russian oilfields</td>\n",
       "      <td>http://www.thehindu.com/business/Economy/hpcl-...</td>\n",
       "      <td>1970-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421970</th>\n",
       "      <td>Govt defers TDS, TCS under GST to ensure smoot...</td>\n",
       "      <td>http://www.thehindu.com/business/govt-defers-t...</td>\n",
       "      <td>1970-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421971 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 headline  \\\n",
       "0       Production outages in Asia lend slight support...   \n",
       "1       UK consumers suffer longest decline in spendin...   \n",
       "2       Market Now: Gammon Infra, GVK Power Infra surg...   \n",
       "3       Global markets: Brightening economy sets euro ...   \n",
       "4       Relying on schemes like Swachh Bharat alone wo...   \n",
       "...                                                   ...   \n",
       "421966  Chennai Angels invests in SparesHub owner Iradium   \n",
       "421967                      Task force formed on aviation   \n",
       "421968         Biological E in vaccine tie-up with Takeda   \n",
       "421969            HPCL joins talks for Russian oilfields    \n",
       "421970  Govt defers TDS, TCS under GST to ensure smoot...   \n",
       "\n",
       "                                                      url publish_date  \n",
       "0       http://feeds.reuters.com/~r/reuters/INbusiness...   2017-06-30  \n",
       "1       http://feeds.reuters.com/~r/reuters/INbusiness...   2017-06-30  \n",
       "2       http://economictimes.indiatimes.com/markets/st...   2017-06-30  \n",
       "3       http://feeds.reuters.com/~r/reuters/INbusiness...   2017-06-30  \n",
       "4       http://www.business-standard.com/article/econo...   2017-06-30  \n",
       "...                                                   ...          ...  \n",
       "421966  http://www.thehindu.com/business/Industry/chen...   1970-01-01  \n",
       "421967  http://www.thehindu.com/business/Economy/task-...   1970-01-01  \n",
       "421968  http://www.thehindu.com/business/Economy/biolo...   1970-01-01  \n",
       "421969  http://www.thehindu.com/business/Economy/hpcl-...   1970-01-01  \n",
       "421970  http://www.thehindu.com/business/govt-defers-t...   1970-01-01  \n",
       "\n",
       "[421971 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['publish_date'] = pd.to_datetime(news_df['publish_date'], errors='coerce').dt.date\n",
    "\n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_financial_data(file_path):\n",
    "    # Load the financial data and skip the first row that contains column names\n",
    "    df_extrema = pd.read_csv(file_path, header=0, names=[\"date\",\"type\",\"ticker\",\"price\"])\n",
    "\n",
    "    # Convert the date column to datetime format (ensure it's timezone-aware, if needed)\n",
    "    df_extrema['date'] = pd.to_datetime(df_extrema['date'], errors='coerce')\n",
    "\n",
    "    \n",
    "# Convert the 'date' column in df_extrema to datetime, and then extract only the date part\n",
    "    df_extrema['date'] = pd.to_datetime(df_extrema['date'], errors='coerce').dt.date\n",
    "    df_extrema\n",
    "    \n",
    "    return df_extrema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_for_extrema(df_extrema, news_df):\n",
    "    results = []\n",
    "    \n",
    "    # Iterate through each extrema entry\n",
    "    for _, row in df_extrema.iterrows():\n",
    "        extrema_date = row['date']\n",
    "        # Filter news articles published within ±2 days of the extrema date\n",
    "        start_date = extrema_date - timedelta(days=2)\n",
    "        end_date = extrema_date + timedelta(days=2)\n",
    "        \n",
    "        # Filter news articles within the date range\n",
    "        relevant_news = news_df[(news_df['publish_date'] >= start_date) & (news_df['publish_date'] <= end_date)]\n",
    "        \n",
    "        # If there are relevant news articles, append them to the results list\n",
    "        if not relevant_news.empty:\n",
    "            results.append({\n",
    "                'extrema_date': extrema_date,\n",
    "                'extrema_type': row['type'],\n",
    "                'ticker': row['ticker'],\n",
    "                'extrema_price': row['price'],\n",
    "                'relevant_news': relevant_news[['headline', 'publish_date', 'url']]\n",
    "            })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get news articles within ±2 days of each extrema (ignoring the time)\n",
    "def get_news_for_extrema(df_extrema, news_df):\n",
    "    results = []\n",
    "    \n",
    "    # Iterate through each extrema entry\n",
    "    for _, row in df_extrema.iterrows():\n",
    "        extrema_date = row['date']\n",
    "        \n",
    "        # Filter news articles published within ±2 days of the extrema date\n",
    "        start_date = extrema_date - timedelta(days=2)\n",
    "        end_date = extrema_date + timedelta(days=2)\n",
    "        \n",
    "        # Filter news articles within the date range\n",
    "        relevant_news = news_df[(news_df['publish_date'] >= start_date) & (news_df['publish_date'] <= end_date)]\n",
    "        \n",
    "        # If there are relevant news articles, append them to the results list\n",
    "        if not relevant_news.empty:\n",
    "            results.append({\n",
    "                'extrema_date': extrema_date,\n",
    "                'extrema_type': row['type'],\n",
    "                'ticker': row['ticker'],\n",
    "                'extrema_price': row['price'],\n",
    "                'relevant_news': relevant_news[['headline', 'publish_date', 'url']]\n",
    "            })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sh\\AppData\\Local\\Temp\\ipykernel_11984\\3019678246.py:6: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df_extrema['date'] = pd.to_datetime(df_extrema['date'], errors='coerce')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>ticker</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-02-03</td>\n",
       "      <td>local_minima</td>\n",
       "      <td>^IXIC</td>\n",
       "      <td>3996.959961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-03-03</td>\n",
       "      <td>local_minima</td>\n",
       "      <td>^IXIC</td>\n",
       "      <td>4277.299805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaT</td>\n",
       "      <td>local_minima</td>\n",
       "      <td>^IXIC</td>\n",
       "      <td>4245.399902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaT</td>\n",
       "      <td>local_minima</td>\n",
       "      <td>^IXIC</td>\n",
       "      <td>4151.229980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaT</td>\n",
       "      <td>local_minima</td>\n",
       "      <td>^IXIC</td>\n",
       "      <td>3999.729980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>NaT</td>\n",
       "      <td>local_maxima</td>\n",
       "      <td>^IXIC</td>\n",
       "      <td>18712.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>2024-11-11</td>\n",
       "      <td>local_maxima</td>\n",
       "      <td>^IXIC</td>\n",
       "      <td>19298.759766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>2024-12-16</td>\n",
       "      <td>local_maxima</td>\n",
       "      <td>^IXIC</td>\n",
       "      <td>20173.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>2024-12-16</td>\n",
       "      <td>global_max</td>\n",
       "      <td>^IXIC</td>\n",
       "      <td>20173.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>2014-02-03</td>\n",
       "      <td>global_min</td>\n",
       "      <td>^IXIC</td>\n",
       "      <td>3996.959961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date          type ticker         price\n",
       "0    2014-02-03  local_minima  ^IXIC   3996.959961\n",
       "1    2014-03-03  local_minima  ^IXIC   4277.299805\n",
       "2           NaT  local_minima  ^IXIC   4245.399902\n",
       "3           NaT  local_minima  ^IXIC   4151.229980\n",
       "4           NaT  local_minima  ^IXIC   3999.729980\n",
       "..          ...           ...    ...           ...\n",
       "313         NaT  local_maxima  ^IXIC  18712.750000\n",
       "314  2024-11-11  local_maxima  ^IXIC  19298.759766\n",
       "315  2024-12-16  local_maxima  ^IXIC  20173.890625\n",
       "316  2024-12-16    global_max  ^IXIC  20173.890625\n",
       "317  2014-02-03    global_min  ^IXIC   3996.959961\n",
       "\n",
       "[318 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_financial_data('extrema_dates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sh\\AppData\\Local\\Temp\\ipykernel_11984\\3019678246.py:6: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df_extrema['date'] = pd.to_datetime(df_extrema['date'], errors='coerce')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_extrema' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m load_financial_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextrema_dates.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m news_for_extrema \u001b[38;5;241m=\u001b[39m get_news_for_extrema(\u001b[43mdf_extrema\u001b[49m, news_df)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Example: Display news for the first extrema in the result\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m news_for_extrema:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_extrema' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "news_for_extrema = get_news_for_extrema(df_extrema, news_df)\n",
    "\n",
    "# Example: Display news for the first extrema in the result\n",
    "if news_for_extrema:\n",
    "    print(news_for_extrema[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'DatetimeArray' and 'datetime.date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Match the news with the financial data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m matched_news_df \u001b[38;5;241m=\u001b[39m \u001b[43mclean_and_match_news\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnews_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_extrema\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[55], line 16\u001b[0m, in \u001b[0;36mclean_and_match_news\u001b[1;34m(news_df, df_extrema)\u001b[0m\n\u001b[0;32m     13\u001b[0m     extrema_date \u001b[38;5;241m=\u001b[39m extrema_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Find the closest news article by comparing dates\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     closest_news \u001b[38;5;241m=\u001b[39m news_df\u001b[38;5;241m.\u001b[39mloc[(\u001b[43mnews_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpublish_date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mextrema_date\u001b[49m)\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39midxmin()]\n\u001b[0;32m     18\u001b[0m     matched_news\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextrema_date\u001b[39m\u001b[38;5;124m\"\u001b[39m: extrema_date,\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextrema_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: extrema_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextrema_type\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnews_publish_date\u001b[39m\u001b[38;5;124m\"\u001b[39m: closest_news[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublish_date\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     26\u001b[0m     })\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Step 4: Create a DataFrame to show the matched results\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\arraylike.py:194\u001b[0m, in \u001b[0;36mOpsMixin.__sub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sub__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\series.py:6135\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[0;32m   6134\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other)\n\u001b[1;32m-> 6135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\base.py:1382\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1379\u001b[0m     rvalues \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(rvalues\u001b[38;5;241m.\u001b[39mstart, rvalues\u001b[38;5;241m.\u001b[39mstop, rvalues\u001b[38;5;241m.\u001b[39mstep)\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1382\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\ops\\array_ops.py:273\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m# NB: We assume that extract_array and ensure_wrapped_if_datetimelike\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m#  have already been called on `left` and `right`,\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m#  and `maybe_prepare_scalar_for_op` has already been called on `right`\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# We need to special-case datetime64/timedelta64 dtypes (e.g. because numpy\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# casts integer dtypes to timedelta64 when operating with timedelta64 - GH#22390)\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    267\u001b[0m     should_extension_dispatch(left, right)\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, (Timedelta, BaseOffset, Timestamp))\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;66;03m# Timedelta/Timestamp and other custom scalars are included in the check\u001b[39;00m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m# because numexpr will fail on it, see GH#31457\u001b[39;00m\n\u001b[1;32m--> 273\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;66;03m# TODO we should handle EAs consistently and move this check before the if/else\u001b[39;00m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;66;03m# (https://github.com/pandas-dev/pandas/issues/41165)\u001b[39;00m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;66;03m# error: Argument 2 to \"_bool_arith_check\" has incompatible type\u001b[39;00m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[0;32m    279\u001b[0m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'DatetimeArray' and 'datetime.date'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Match the news with the financial data\n",
    "matched_news_df = clean_and_match_news(news_df, df_extrema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matched_news_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Display the matched results\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmatched_news_df\u001b[49m\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'matched_news_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the matched results\n",
    "print(matched_news_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
